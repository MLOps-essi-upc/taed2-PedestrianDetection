{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelling**"
      ],
      "metadata": {
        "id": "oaRpkllkfjWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intended use of this .ipynb file is to take the processed data file and train multiple models aimed at detecting pedestrians, all while employing Mlflow tracking."
      ],
      "metadata": {
        "id": "FWVCvN_3g6xf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the processed data"
      ],
      "metadata": {
        "id": "HR88erc7h5Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We retrieve the data from the google drive folder.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oir1HgKKteK8",
        "outputId": "e72670e2-4fe6-4cb1-877b-c41e94639043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the path with the correct path for each individual (the path has been set up to work for all three members of the team)\n",
        "\n",
        "DATA_FOLDER = \"/content/drive/MyDrive/TAED2-PedestrianDetection/Datasets/PennFudan/Processed data\""
      ],
      "metadata": {
        "id": "vsjKYSSOuSlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# TorchVision repo is downloaded to use some reference files\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.15.1\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAsMqXvbyZE0",
        "outputId": "ea44173d-27ff-4012-9650-4cd1b78bae31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n",
            "HEAD is now at 42759b1cc8 Version number bump for vision (#7419)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the directory to the current Python path\n",
        "import sys\n",
        "\n",
        "sys.path.append(DATA_FOLDER)"
      ],
      "metadata": {
        "id": "FpAJoNRzuW1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using this code we load each dataset from their respective file.\n",
        "# Download preprocessed data\n",
        "\n",
        "import pickle\n",
        "from PedestrianDatasetClass import PedestrianDataset  # Import the required class\n",
        "\n",
        "with open(DATA_FOLDER + '/training_dataset.pkl', 'rb') as file:\n",
        "    training_dataset = pickle.load(file)\n",
        "\n",
        "with open(DATA_FOLDER + '/validation_dataset.pkl', 'rb') as file:\n",
        "    validation_dataset = pickle.load(file)\n",
        "\n",
        "with open(DATA_FOLDER + '/testing_dataset.pkl', 'rb') as file:\n",
        "    testing_dataset = pickle.load(file)\n",
        "\n"
      ],
      "metadata": {
        "id": "0Wc_wSwQtX4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwY0T7HDE5Vk",
        "outputId": "aa2b6327-ad97-4048-a19b-6ca495faf95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.5294, 0.3373, 0.3098,  ..., 0.5725, 0.5216, 0.4706],\n",
              "          [0.3922, 0.2784, 0.3059,  ..., 0.5647, 0.5098, 0.4627],\n",
              "          [0.2824, 0.2353, 0.2863,  ..., 0.5608, 0.5059, 0.4588],\n",
              "          ...,\n",
              "          [0.5569, 0.5569, 0.5412,  ..., 0.4510, 0.4510, 0.4510],\n",
              "          [0.5490, 0.5451, 0.5373,  ..., 0.4392, 0.4392, 0.4392],\n",
              "          [0.5333, 0.5373, 0.5333,  ..., 0.4353, 0.4353, 0.4353]],\n",
              " \n",
              "         [[0.6314, 0.4392, 0.4118,  ..., 0.5686, 0.5176, 0.4667],\n",
              "          [0.4941, 0.3804, 0.4078,  ..., 0.5608, 0.5059, 0.4588],\n",
              "          [0.3765, 0.3294, 0.3804,  ..., 0.5569, 0.5020, 0.4549],\n",
              "          ...,\n",
              "          [0.5608, 0.5608, 0.5451,  ..., 0.4549, 0.4549, 0.4549],\n",
              "          [0.5529, 0.5490, 0.5412,  ..., 0.4431, 0.4431, 0.4431],\n",
              "          [0.5373, 0.5412, 0.5373,  ..., 0.4392, 0.4392, 0.4392]],\n",
              " \n",
              "         [[0.5255, 0.3333, 0.3059,  ..., 0.5529, 0.5020, 0.4510],\n",
              "          [0.3961, 0.2745, 0.3098,  ..., 0.5451, 0.4902, 0.4431],\n",
              "          [0.2902, 0.2353, 0.2941,  ..., 0.5412, 0.4863, 0.4392],\n",
              "          ...,\n",
              "          [0.5686, 0.5686, 0.5529,  ..., 0.4627, 0.4627, 0.4627],\n",
              "          [0.5608, 0.5569, 0.5490,  ..., 0.4510, 0.4510, 0.4510],\n",
              "          [0.5451, 0.5490, 0.5451,  ..., 0.4471, 0.4471, 0.4471]]]),\n",
              " {'boxes': tensor([[111.,  68., 217., 345.],\n",
              "          [377.,  75., 528., 376.],\n",
              "          [316., 107., 346., 191.]]),\n",
              "  'labels': tensor([1, 1, 1]),\n",
              "  'masks': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           ...,\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0]],\n",
              "  \n",
              "          [[0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           ...,\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0]],\n",
              "  \n",
              "          [[0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           ...,\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0],\n",
              "           [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
              "  'image_id': tensor([6]),\n",
              "  'area': tensor([29362., 45451.,  2520.]),\n",
              "  'iscrowd': tensor([0, 0, 0])})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Mlflow"
      ],
      "metadata": {
        "id": "gTIekjnNiF1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDLQesUNOQIL",
        "outputId": "b23488db-7724-46a2-bfe4-a2db04fe3475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.7.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.17.8)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.37)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.1)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.12.0)\n",
            "Requirement already satisfied: docker<7,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.1.3)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.20)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<14,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.4.4)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: gunicorn<22 in /usr/local/lib/python3.10/dist-packages (from mlflow) (21.2.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.16)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow) (1.6.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow) (2.3.7)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow) (2.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.16.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import mlflow.sklearn\n",
        "from mlflow import log_metric, log_param, log_params, log_artifacts"
      ],
      "metadata": {
        "id": "E-qYkh8b_EzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku-c8rOmZbPG",
        "outputId": "170fbf2f-9d98-4245-9f2a-c7d459e73a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the repository to load the .env file\n",
        "!git clone https://github.com/MLOps-essi-upc/taed2-PedestrianDetection.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIxWR19Raud5",
        "outputId": "39ddc486-d9c9-4867-fef5-141732163f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'taed2-PedestrianDetection' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "# Run your MLflow script (script.py)\n",
        "os.system(\"python script.py\")\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "# Set the MLflow tracking URI and authentication variables\n",
        "mlflow_tracking_uri = os.environ[\"MLFLOW_TRACKING_URI\"]\n",
        "mlflow_username = os.environ[\"MLFLOW_TRACKING_USERNAME\"]\n",
        "mlflow_password = os.environ[\"MLFLOW_TRACKING_PASSWORD\"]\n",
        "\n",
        "# Set up MLflow with the loaded credentials\n",
        "mlflow.set_tracking_uri(mlflow_tracking_uri)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "gsLd2f25Xf4Y",
        "outputId": "8741e2eb-bcd9-44be-f066-65a6cd6328f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c6d927d3a991>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Set the MLflow tracking URI and authentication variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmlflow_tracking_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MLFLOW_TRACKING_URI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmlflow_username\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MLFLOW_TRACKING_USERNAME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmlflow_password\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MLFLOW_TRACKING_PASSWORD\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'MLFLOW_TRACKING_URI'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the connection is correct with a 'prova' experiment\n",
        "\n",
        "# Start an MLflow experiment\n",
        "mlflow.set_experiment('prova')\n",
        "mlflow.start_run()\n",
        "\n",
        "# Your machine learning code here\n",
        "# For demonstration purposes, let's say you're training a simple model\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a simple RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Log the model and metrics in MLflow\n",
        "mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
        "mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "# End the MLflow run\n",
        "mlflow.end_run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgZonOIdOqKW",
        "outputId": "709f0987-8d34-4169-e4d8-54ce4b824c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/10/01 08:48:04 INFO mlflow.tracking.fluent: Experiment with name 'prova' does not exist. Creating a new experiment.\n",
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        }
      ]
    }
  ]
}